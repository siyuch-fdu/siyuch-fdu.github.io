<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-size:32px;
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WJFX2BFB9X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WJFX2BFB9X');
</script>
	<title>Manga Generation via Layout-controllable Diffusion</title>
	<meta property="og:image" content="./resources/fig1.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Manga Generation via Layout-controllable Diffusion" />
	<meta property="og:description" content="S. Chen, Y. Zhong, Z. Jie, X. Chu, H. Ren, X. Wei, W. Xie, L. Ma" />
</head>

<body>
	<br>
	<center>
		<span style="font-size:34px">Manga Generation via Layout-controllable Diffusion</span>
		<br>
		<br>

		<table align=center width=1000px>
			<table align=center width=1000px>
				<tr>
					<td align=center width=250px>
						<center>
							<span style="font-size:22px"><a href="https://fcjian.github.io/">
							Siyu Chen</a></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:22px"><a href="https://y-zhong.info/">
							Dengjie Li</a></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:22px"><a href="https://y-zhong.info/">
							Zenghao Bao</a></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:22px"><a href="https://y-zhong.info/">
							Yao Zhou</a></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:22px"><a href="https://y-zhong.info/">
							Lingfeng Tan</a></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:22px"><a href="https://y-zhong.info/">
							Yujie Zhong</a></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:22px"><a href="https://y-zhong.info/">
							Zheng Zhao</a></span>
						</center>
					</td>
				</tr>
			</table>

			</tbody></table><br>
		  	<table align="center" width="800px">
				<tbody><tr>
					<td align="center" width="300px">
				  		<center>
							<span style="font-size:22px">Meituan Inc.</span>
						</center>
					</td>
			</tr></tbody></table>

			<br>

			<table align=center width=250px>
				<br>
				<tr>
					<span style="font-size:22px">
						<a href="https://arxiv.org/abs/2402.05937">ArXiv</a> |
						<a href="https://github.com/fcjian/InstaGen">Code</a> |
						<a href="./resources/bibtex.txt">Bibtex</a><br>
					</span>
				</tr>
			</table>
		</table>
	</center>
	<br>
	<center>
		<table align=center width=1000px>
			<tr>
				<td width=1000px>
					<center>
						<img src="./resources/fig1.bmp" alt="clean-usnob" width="720">
					</center>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Generating comics through text is widely studied. However, there are few studies on generating multi-panel Manga (Japanese comics) solely based on plain text. Japanese manga contains multiple panels on a single page, with characteristics such as coherence in storytelling, reasonable and diverse page layouts, consistency in characters, and semantic correspondence between panel drawings and panel scripts. Therefore, generating manga poses a significant challenge. This paper presents the manga generation task and constructs the Manga109Story dataset for studying manga generation solely from plain text. Additionally, we propose MangaDiffusion to facilitate the intra-panel and inter-panel information interaction during the manga generation process. The results show that our method particularly ensures the number of panels, reasonable and diverse page layouts. Based on our approach, there is potential to converting a large amount of textual stories into more engaging manga readings, leading to significant application prospects. Our code and dataset will be made publicly available soon.
			</td>
		</tr>
	</table>
	<br>

	<hr>
	<center><h1>Architecture</h1></center>

	<table align=center width=850px>
		<tr>
			<td>
				To simultaneously generate the images and object bounding boxes, we propose a novel instance-level grounding module, which aligns the text embedding of category name with the regional visual features from image synthesizer, and infers the coordinates for the objects in synthetic images. To further improve the alignment towards objects of arbitrary category, we adopt self-training to tune the grounding module on object categories not existing in the real dataset. As a result, the proposed model, termed as InstaGen, can automatically generate images along with bounding boxes for object instances, and construct synthetic dataset at scale, leading to improved ability when training detectors on it.
			</td>
		</tr>
	</table>
	<table align=center width=750px>
		<center>
			<tr>
				<td>
				<center>
					<td><img class="round" style="width:850px" src="./resources/fig4.bmp"/></td>
				</center>
				</td>
			</tr>
		</center>
	</table>

	<hr>
	<center><h1>Manga109Story Dataset</h1></center>

	<table align=center width=850px>
		<tr>
			<td>
				Visualization of the synthetic dataset generated by our InstaGen. The bounding-boxes with green denote the objects from <font color=#00FF00><b>base</b></font> categories, while the ones with red denote the objects from <font color=#FF0000><b>novel</b></font>  categories.
			</td>
		</tr>
	</table>
	<table align=center width=750px>
		<center>
			<tr>
				<td>
				<center>
					<td><img class="round" style="width:850px" src="./resources/fig2.bmp"/></td>
				</center>
				</td>
			</tr>
		</center>
	</table>

	<hr>
	<center><h1>Results</h1></center>

	<table align=center width=850px>
		<tr>
			<td>
				<b>R1</b>: Visualization results of MangaDiffuion and other T2I methods. Each row represents a story, and the text above the images shows the number of panels and the corresponding captions for each panel. It can be observed from the figures that our method performs well in terms of panel quantity control and panel layout diversity.
			</td>
		</tr>
	</table>
	<table align=center width=750px>
		<center>
			<tr>
				<td>
				<center>
					<td><img class="round" style="width:750px" src="./resources/fig5.bmp"/></td>
				</center>
				</td>
			</tr>
		</center>
	</table>

	<br>
	<table align=center width=850px>
		<tr>
			<td>
				<b>R2</b>: Comparison between T2I SOTAs and our proposed MangaDiffusion on Manga109Story test set. The Pixart-$\Sigma$ \cite{chen2024pixart} is fine-tuned using Manga109Story train set for 120 epochs, and the other SOTAs are inference directly without any fine-tuning.
			</td>
		</tr>
	</table>
	<table align=center width=350px>
		<center>
			<tr>
				<td>
				<center>
					<td><img class="round" style="width:350px" src="./resources/tab1.png"/></td>
				</center>
				</td>
			</tr>
		</center>
	</table>

	<br>

	<table align=center width=750px>
		<center>
			<tr>
				<td>
				<center>
			</tr>
		</center>
	</table>

	<hr>
	<table align=center width=800px>
		<center><h1>Publication</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">C. Feng, Y. Zhong, Z. Jie, W. Xie, L. Ma<br>
				<b>InstaGen: Enhancing Object Detection by Training on Synthetic Dataset</b><br>
				<em>CVPR</em> 2024
				<br>
				<a href="https://arxiv.org/abs/2402.05937">ArXiv</a> |
				<a href="https://github.com/fcjian/InstaGen">Code</a> |
				<a href="./resources/bibtex.txt">Bibtex</a><br>
				<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>
	<br>

	<table style="width:95%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <tr>
		<td style="padding:0px">
		  <br>
		  <p style="text-align:right;font-size:small;">
			Webpage template modified from <a href="https://github.com/richzhang/webpage-template/">here</a>.
		  </p>
		</td>
	  </tr>
	</tbody></table>

<br>
</body>
</html>
